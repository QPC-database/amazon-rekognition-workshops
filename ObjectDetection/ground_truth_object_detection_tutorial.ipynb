{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This sample notebook takes you through an end-to-end workflow to demonstrate the functionality of SageMaker Ground Truth and Amazon Rekognition Custom Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import tarfile\n",
    "import boto3\n",
    "import os\n",
    "from sagemaker import get_execution_role\n",
    "import sagemaker\n",
    "from IPython.display import HTML, display, Image as IImage\n",
    "from PIL import Image, ImageDraw, ImageFont\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Images to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'sagemaker-aiml' ## Updates the value with the bucket name created earlier in the lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uploading Licensed Images for raw data\n",
    "region = boto3.Session().region_name    \n",
    "source_dir = '../images/raw-data/LicensedImages-CreativeCommons'\n",
    "dest_dir = 'raw-data/images'\n",
    "file_list = os.listdir(source_dir)\n",
    "s3_client = boto3.client('s3', region_name=region)\n",
    "for file in file_list :   \n",
    "    if file != '.ipynb_checkpoints':\n",
    "        response = s3_client.upload_file(source_dir+'/'+file, bucket_name, dest_dir+\"/\"+file)\n",
    "        print (file + ' uploaded')\n",
    "print('Raw Data Upload Complete to '+bucket_name+'/'+dest_dir)\n",
    "\n",
    "## Uploading Non-Licensed Images for raw data\n",
    "source_dir = '../images/raw-data/LicenseNotNeeded_Images'\n",
    "dest_dir = 'raw-data/images'\n",
    "file_list = os.listdir(source_dir)\n",
    "s3_client = boto3.client('s3', region_name=region)\n",
    "for file in file_list : \n",
    "    if file != '.ipynb_checkpoints':\n",
    "        response = s3_client.upload_file(source_dir+'/'+file, bucket_name, dest_dir+\"/\"+file)\n",
    "        print (file + ' uploaded')\n",
    "print('Raw Data Upload Complete to '+bucket_name+'/'+dest_dir)\n",
    "\n",
    "\n",
    "\n",
    "## Uploading Test Data\n",
    "source_dir = '../images/test-data'\n",
    "dest_dir = 'test-data/images'\n",
    "file_list = os.listdir(source_dir)\n",
    "s3_client = boto3.client('s3', region_name=region)\n",
    "for file in file_list : \n",
    "    response = s3_client.upload_file(source_dir+'/'+file, bucket_name, dest_dir+\"/\"+file)\n",
    "    print (file + ' uploaded')\n",
    "print('Test Data Upload Complete to '+bucket_name+'/'+dest_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at one of the images"
   ]
  },
  {
   "source": [
    "imageName = \"raw-data/images/800px-Woodpeckers-Telephone-Cable.jpg\"\n",
    "display(IImage(url=s3_client.generate_presigned_url('get_object', Params={'Bucket': bucket_name, 'Key': imageName})))"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "## Detect Object using Amazon Rekogniton\n",
    "#### Attach IAM Managed Policy \n",
    "- Click on the generated URL\n",
    "- Click on **Attach policies** button\n",
    "- Search for **Rekog** in **Filter policies** bar\n",
    "- Select **AmazonRekognitionFullAccess** and click on **Attach Policy**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role_name = get_execution_role().split('/')[1]\n",
    "job_url = \"https://console.aws.amazon.com/iam/home?#/roles/\"+role_name+\"?section=permissions\"\n",
    "print (job_url) "
   ]
  },
  {
   "source": [
    "<img src=\"../lab-images/15.png\">\n",
    "<img src=\"../lab-images/16.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### Assume Role\n",
    "- Click on the generated URL\n",
    "- Click on **Edit trust relationship** button\n",
    "- Edit Policy with Service as **[\"sagemaker.amazonaws.com\",\"rekognition.amazonaws.com\"]**\n",
    "- Click on **Update Trust Policy** button"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_url = \"https://console.aws.amazon.com/iam/home?#/roles/\"+role_name+\"?section=trust\"\n",
    "print (job_url) "
   ]
  },
  {
   "source": [
    "<img src=\"../lab-images/17.png\" width=\"600\">\n",
    "<img src=\"../lab-images/18.png\" width=\"600\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Lets look at Object Detection"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call Amazon Rekognition to detect objects in the image\n",
    "# https://docs.aws.amazon.com/rekognition/latest/dg/API_DetectLabels.html\n",
    "imageName = \"raw-data/images/4278289454_d4bcb08484_o.jpg\"\n",
    "\n",
    "# Init clients\n",
    "rekognition = boto3.client('rekognition')\n",
    "\n",
    "detectLabelsResponse = rekognition.detect_labels(\n",
    "    Image={\n",
    "        'S3Object': {\n",
    "            'Bucket': bucket_name,\n",
    "            'Name': imageName,\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "imageName = \"raw-data/images/4278289454_d4bcb08484_o.jpg\"\n",
    "display(IImage(url=s3_client.generate_presigned_url('get_object', Params={'Bucket': bucket_name, 'Key': imageName})))\n",
    "\n",
    "##Display list of Objects\n",
    "print(\"Detected object:\")\n",
    "for label in detectLabelsResponse[\"Labels\"]:\n",
    "        print(\"- {} (Confidence: {})\".format(label[\"Name\"], label[\"Confidence\"]))"
   ]
  },
  {
   "source": [
    "As you can notice in the above response that Amazon Rekognition service detected objects in the provided image but did not detect the holes as an object of interest. This means we need to use Amazon Rekognition Custom Labels to detect custom labels in the image. Typically, you would need to identify the correct machine learning algorithm, machine learning model, tune the model and perform hyperparameter tuning. All of this is handled for you with just few lines of code in Amazon Rekognition Custom Labels. Let's see it in action."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ground Truth labeling job\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "Part or all of your images will be annotated by human annotators. It is essential to provide good instructions that help the annotators give you the annotations you want. Good instructions are:\n",
    "\n",
    "Concise. We recommend limiting verbal/textual instruction to two sentences, and focusing on clear visuals.\n",
    "Visual. In the case of image classification, we recommend providing one labeled image in each of the classes as part of the instruction.\n",
    "When used through the AWS Console, Ground Truth helps you create the instructions using a visual wizard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Labeling Workforce\n",
    "- Select **'Labeling workforces'** then click the **'Private'** tab.\n",
    "- On the **'Private'** tab click **'Create private team'**\n",
    "\n",
    "![labeling workforce](../lab-images/1a.png)\n",
    "\n",
    "On the **'Create private team'** page\n",
    "- Enter the **'Team name'** as **Labeling-experts**\n",
    "- Click **Create private team**\n",
    "\n",
    "![Create private team](../lab-images/1b.png)\n",
    "\n",
    "Select **Invite new workers**\n",
    "![Create private team](../lab-images/1c.png)\n",
    "\n",
    "On the **Add workers by email address** page \n",
    "- Add your **email address** to invite private annotators to access the job. For the purpose of this exercise, you can use your own email address. Typically, this will be the list of email addresses of workers in your organization.\n",
    "- Click **Invite new workers**\n",
    "\n",
    "![Create private team](../lab-images/1d.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ground Truth Label Job\n",
    "In the left hand menu select **Labeling Job**\n",
    "![Create Labeling Job](../lab-images/1.png)\n",
    "\n",
    "Click **Create labeling job**\n",
    "![Label Job](../lab-images/2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify Job Parameters\n",
    "- Specify Job Name - **'aws-workshops-woodpecker-holes'**\n",
    "- Check the box next to \"I want to specify a label attribute name different from the labeling job name.\"\n",
    "- Specify a value of **'labels'** in the \"Label attribute name\" field\n",
    "- Under \"Input data setup\" select \"**Automated data setup**\"\n",
    "- For \"S3 location for input datasets\" specify the S3 location of images - **'s3://{your-bucket-name}/raw-data/images/'**\n",
    "- Next select \"Specify a new location\" under \"S3 location for output datasets\" and specify the output location for annotated data - **'s3://{your-bucket-name}/annotated-data/'**\n",
    "- For \"Data type\" select \"images\"\n",
    "\n",
    "**Note:** When you see **{your-bucket-name}** replace it with the name of the bucket that you created earlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../lab-images/labelingJob.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create IAM Role\n",
    "- Select the option to **create a new role**\n",
    "- Specify S3 Bucket Name - **'{your-bucket-name}'** \n",
    "- Click on **Create** button"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete Data setup\n",
    "- Click on \"**Complete Data Setup**\". This will created the image manifest file and update the S3 input location path. Wait for \"**Input data connection successful**\"\n",
    "\n",
    "<img src=\"../lab-images/completedatasetup.png\">\n",
    "\n",
    "\n",
    "### Additional Configuration\n",
    "- Expand **Additional Configuration** \n",
    "- Validate that **Full dataset** is selected (This is used to specify whether you want to provide all the images to labeling job or a sub set of images based on filters or random sampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../lab-images/4.png\" width=\"600\">\n",
    "<img src=\"../lab-images/5.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeling Task \n",
    "- From the **Task type** drop down, select **Image**. Since you need to do annotation on images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../lab-images/6.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../lab-images/7.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task Selection\n",
    "- This is Object Detection use case so you need to select **Bounding box** option  \n",
    "- Leave other options as default and click on **Next** button"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../lab-images/8.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select workers and configure tool\n",
    "- Select **Private** in **Worker types**. For this lab, you will select an internal workforce to annotate the images. You have the option to select Public contractual workforce i.e **Amazon Mechanical Turk** or Partner workforce i.e. **Vendor managed** depending on your use case.\n",
    "- In **Private teams** select the team name - **'labeling-experts'**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../lab-images/9.png\" width=\"600\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeling Instructions Template\n",
    "- Leave other configurations default and scroll down to **Bounding box labeling tool**\n",
    "- Add two labels as shown below - **'hole'** and **'no_hole'**\n",
    "- Add detailed instructions in the **Description tab** for providing instructions to the workers - For example, you can specify - **You need to label woodpecker hole in the provided image. Please ensure that you select label 'hole' and draw the box around the woodpecker hole just to fit the hole for better quality of label data. You also need to label other areas which look similar to woodpecker holes but are not woodpecker holes with label 'no_hole'**\n",
    "- You can also *optionally* provide examples of Good and Bad labeling image. You need to make sure that these images are publicly accessible.\n",
    "- Click on **Create** button\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../lab-images/10.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Labeling Job\n",
    "- Once you have successfully created the job, you will see that the **status** of the job is **\"InProgress\"**. This means that the job is created and the private workforce is notified via **email** regarding the task assigned to them. Since in this case, you have assigned the task to yourself. You should have received email with instructions to login to Ground Truth Labeling project\n",
    "- **Open the email** and click on the **link** provided\n",
    "- Enter **username** and **password** provided in the email. You may have to change the one time password provided in the email with a new password after login\n",
    "- After you login, you will see the below screen\n",
    "- Click on **Start working** button"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../lab-images/11.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeling Task\n",
    "- You can use the provided tools to **Zoom in**, **Zoom out**, **Move** and **Box** sections in the images.\n",
    "- You need to first select a **label** i.e. either **hole** or **no_hole** and then draw box in the image to annotate.\n",
    "- Once you are annotating the required objects, click on **Submit** button"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../lab-images/12.png\" heigth=\"900\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete Labeling Task\n",
    "- You need to ensure that the bounding box is just enough to bound the object of interest\n",
    "- Everytime you need to drsw bounding box, you need to first select the label on the right panel and then draw box around the object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../lab-images/13.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Check Labeling Job Status\n",
    "A Ground Truth job can take a few hours to complete (if your dataset is larger than 10000 images, it can take much longer than that!). One way to monitor the job's progress is through AWS Console. In this notebook, we will use Ground Truth output files to monitor the progress.\n",
    "\n",
    "You can re-evaluate the next cell repeatedly. It sends a `describe_labeling_job` request which should tell you whether the job is completed or not. If it is, then 'LabelingJobStatus' will be 'Completed'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = 'aws-workshops-woodpecker-holes' \n",
    "sagemaker_client = boto3.client('sagemaker')\n",
    "sagemaker_client.describe_labeling_job(LabelingJobName=job_name)['LabelingJobStatus']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect Labeled Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_url = \"https://\"+region+\".console.aws.amazon.com/sagemaker/groundtruth?region=\"+region+\"#/labeling-jobs/details/\"+job_name\n",
    "print (job_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeled Data Sets\n",
    "- Once you have labeled all the images, you will be taken to the SageMaker labeling project home page. This page shows you the **Labeled dataset** as shown below\n",
    "- You can see how the different labels are applied. Now, training data for Amazon Rekognition Custom Labels is ready."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../lab-images/14.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review\n",
    "\n",
    "We covered a lot of ground in this notebook! Let's recap what we accomplished. We uploaded images to S3 bucket and used SageMake Ground Truth labeling job to label the images and generated new labels for all of the images in our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python390jvsc74a57bd0aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49",
   "display_name": "Python 3.9.0 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
