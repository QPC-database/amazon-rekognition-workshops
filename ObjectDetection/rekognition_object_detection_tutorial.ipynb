{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This sample notebook takes you through an end-to-end workflow to train model on Amazon Rekognition Custom Labels using data set generated by Amazon GroundTruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import tarfile\n",
    "import boto3\n",
    "import os\n",
    "from sagemaker import get_execution_role\n",
    "import sagemaker\n",
    "from IPython.display import HTML, display, Image as IImage\n",
    "from PIL import Image, ImageDraw, ImageFont, ExifTags, ImageColor\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Upload Images to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'aws-workshops-labels-12345678' ## Update the value with the bucket name created earlier in the lab\n",
    "region = boto3.Session().region_name    \n",
    "s3_client = boto3.client('s3', region_name=region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Skip the below step if you already have images uploaded to your S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uploading Licensed Images for raw data\n",
    "source_dir = '../images/raw-data/LicensedImages-CreativeCommons'\n",
    "dest_dir = 'raw-data/images'\n",
    "file_list = os.listdir(source_dir)\n",
    "for file in file_list :   \n",
    "    if file != '.ipynb_checkpoints':\n",
    "        response = s3_client.upload_file(source_dir+'/'+file, bucket_name, dest_dir+\"/\"+file)\n",
    "        print (file + ' uploaded')\n",
    "print('Raw Data Upload Complete to '+bucket_name+'/'+dest_dir)\n",
    "\n",
    "## Uploading Non-Licensed Images for raw data\n",
    "source_dir = '../images/raw-data/LicenseNotNeeded_Images'\n",
    "dest_dir = 'raw-data/images'\n",
    "file_list = os.listdir(source_dir)\n",
    "s3_client = boto3.client('s3', region_name=region)\n",
    "for file in file_list : \n",
    "    if file != '.ipynb_checkpoints':\n",
    "        response = s3_client.upload_file(source_dir+'/'+file, bucket_name, dest_dir+\"/\"+file)\n",
    "        print (file + ' uploaded')\n",
    "print('Raw Data Upload Complete to '+bucket_name+'/'+dest_dir)\n",
    "\n",
    "## Uploading Test Data\n",
    "source_dir = '../images/test-data'\n",
    "dest_dir = 'test-data/images'\n",
    "file_list = os.listdir(source_dir)\n",
    "s3_client = boto3.client('s3', region_name=region)\n",
    "for file in file_list : \n",
    "    response = s3_client.upload_file(source_dir+'/'+file, bucket_name, dest_dir+\"/\"+file)\n",
    "    print (file + ' uploaded')\n",
    "print('Test Data Upload Complete to '+bucket_name+'/'+dest_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: If you get the following error\n",
    "\n",
    "<img src=\"../lab-images/s3error.png\">\n",
    "\n",
    "Please make sure you have updated the correct **bucket_name** with your bucket\n",
    "\n",
    "### Let's look at one of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageName = \"raw-data/images/800px-Woodpeckers-Telephone-Cable.jpg\"\n",
    "display(IImage(url=s3_client.generate_presigned_url('get_object', Params={'Bucket': bucket_name, 'Key': imageName})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Copy Existing Annotation data to S3 Bucket. \n",
    "\n",
    "### <span style=\"color:red\">Note: If you have completed labeling all the images on GroundTruth and want to use your own labeled data set for training Rekognition model, skip Step 2</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update S3 bucket name in existing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_bucket_name = \"aws-workshops-labels-1234567\" ## DO NOT MODIFY. This value comes from existing manifest file. \n",
    "new_bucket_name = bucket_name\n",
    "!echo \"Occurences of old_bucket_name i.e. $old_bucket_name in original manifest file\"\n",
    "!grep -ir $old_bucket_name ../images/annotated-data/manifests/output/output.manifest | wc -l \n",
    "!sed -i.bak -e \"s/$old_bucket_name/$new_bucket_name/g\" ../images/annotated-data/manifests/output/output.manifest\n",
    "!echo \"Occurences of old_bucket_name i.e. $old_bucket_name in original manifest file\"\n",
    "!grep -ir '$old_bucket_name' ../images/annotated-data/manifests/output/output.manifest | wc -l \n",
    "!echo \"Occurences of new_bucket_name i.e. $new_bucket_name in updated manifest file\"\n",
    "!grep -ir $new_bucket_name ../images/annotated-data/manifests/output/output.manifest | wc -l "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload annotation metadata to S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT = 's3://{}/{}'.format(bucket_name, 'annotated-data')\n",
    "\n",
    "## Replace bucket name in manifest file with new bucket name\n",
    "\n",
    "## Uploading annotation data to S3 bucket\n",
    "!aws s3 cp ../images/annotated-data {OUTPUT} --recursive --quiet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  Create Project in Amazon Rekognition Custom Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Project\n",
    "- On the home page, click on **Use Custom Labels** \n",
    "\n",
    "**Note**: *Make sure you are in same **AWS region** as S3 bucket when creating Rekognition Custom Labels project*\n",
    "- On the next page, click on **Get Started** button\n",
    "- If you are creating using Custom Labels for the first time in this AWS Account, you need to allow service to create S3 bucket. \n",
    "- Specify the name of the project as **aws-workshops-rekognition-custom-labels**\n",
    "- Click on **Create Project** button"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../lab-images/19.png\" width=\"800\">\n",
    "<img src=\"../lab-images/20.png\" width=\"800\">\n",
    "<img src=\"../lab-images/36.png\" width=\"800\">\n",
    "<img src=\"../lab-images/21.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Data Set\n",
    "### (Follow Screenshots below)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Click on **Create dataset** button\n",
    "- Specify name for the dataset as **aws-workshops-gt-data**\n",
    "- Select Option - **Import images labeled by Amazon SageMaker Ground Truth**\n",
    "- Specify the location of the output manifest file generated by SageMaker Ground Truth Labeling Job - **s3://{bucket-name}/annotated-data/manifests/output/output.manifest**\n",
    "- Copy and paste the bucket policy by **copying the generated bucket policy** and **then clicking on hyperlink** in the screenshot - **Paste the policy into the \"Bucket Policy\" section of ...**\n",
    "- Return to **Rekognition Data set creation page** and Click on **submit** button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('S3 location of manifest file - \\n' + 's3://{}/annotated-data/manifests/output/output.manifest'.format(bucket_name))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../lab-images/22.png\" width=\"800\">\n",
    "<img src=\"../lab-images/23.png\" width=\"800\">\n",
    "<img src=\"../lab-images/24.png\" width=\"800\">\n",
    "<img src=\"../lab-images/25.png\" width=\"800\">\n",
    "<img src=\"../lab-images/38.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [OPTIONAL STEP - Only needed if you want to do additional labeling or if you did not label the images previously]\n",
    "#### Add Labels\n",
    "- Click on **Start Labeling** button\n",
    "- Click on **Add** button on the next page\n",
    "- Type Label - **hole** and **no_hole** and save it by clicking on **Save** button\n",
    "- Once done, click on **Exit** button to complete the labeling job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../lab-images/39.png\" width=\"800\">\n",
    "<img src=\"../lab-images/startlabeling.png\" width=\"800\">\n",
    "<img src=\"../lab-images/43.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model\n",
    "- Once the dataset is created, click on **Train model** button to start training the automatically identified model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../lab-images/26.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify dataset for training\n",
    "- Select the **previously created** training dataset from the drop down in **Choose training dataset**. Example - **aws-workshops-gt-data**\n",
    "- Select **Spit training dataset** to spit the data set into training and test data for model training and evaluation\n",
    "- Click on **Train** button to start training model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../lab-images/29.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Status\n",
    "**Note this will take ~1-2 hours depending upon a number of factors**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../lab-images/30.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model and Testing Results\n",
    "- Once the training is completed, click on training model link\n",
    "- On the next page, you will see the model evaluation details, Look at the various values for **F1 score, Precision, Recall**. These values depend on the training data.\n",
    "- Click on **View test results** button to check the results on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../lab-images/31.png\" width=\"800\">\n",
    "<img src=\"../lab-images/32.png\" width=\"800\">\n",
    "<img src=\"../lab-images/33.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to evaluate trained model\n",
    "Reference Docs - https://docs.aws.amazon.com/rekognition/latest/customlabels-dg/tr-metrics-use.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precision** - Precision is the fraction of correct predictions (true positives) over all model predictions (true and false positives) at the assumed threshold for an individual label. As the threshold is increased, the model might make fewer predictions. In general, however, it will have a higher ratio of true positives over false positives compared to a lower threshold. Possible values for precision range from 0–1, and higher values indicate higher precision.\n",
    "\n",
    "**Recall** - Recall is the fraction of your test set labels that were predicted correctly above the assumed threshold. It is a measure of how often the model can predict a custom label correctly when it's actually present in the images of your test set. The range for recall is 0–1. Higher values indicate a higher recall.\n",
    "\n",
    "For the given business problem, you may want higher precision and lower recall. Depending upon training data set, the precision and recall values will differ. You can further improve the model accuracy by following the steps mentioned on https://docs.aws.amazon.com/rekognition/latest/customlabels-dg/tr-improve-model.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect Holes using the trained model\n",
    "\n",
    "To analyze an image with a trained Amazon Rekognition Custom Labels model, you call the DetectCustomLabels API. The result from DetectCustomLabels is a prediction that the image contains specific objects, scenes, or concepts.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get values of **project_arn** , **model_arn** and **version_name** as shown in the below screenshot\n",
    "\n",
    "- Click on Project Version once the model training is completed. It shows **TRAINING_COMPLETED**\n",
    "- Click on **Use Model** tab \n",
    "- Expand **API Code** \n",
    "- Select **Python** and get the values of variables from **Start Model** code\n",
    "\n",
    "<img src=\"../lab-images/44.png\" width=\"800\">\n",
    "<img src=\"../lab-images/45.png\" width=\"800\">\n",
    "<img src=\"../lab-images/46.png\" width=\"800\">\n",
    "<img src=\"../lab-images/47.png\" width=\"800\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project_arn is the ARN of the Custom Labels Project\n",
    "project_arn='YOUR PROJECT ARN'\n",
    "\n",
    "# model_arn is the ARN of the Model we want to use from the project we used for custom labels\n",
    "model_arn='YOUR MODEL ARN'\n",
    "\n",
    "# version_name is the custom labeling project name (something like: aws-workshops-rekognition-custom-labels.2021-05-16T11.23.30)\n",
    "version_name='YOUR PROJECT VERSION NAME'\n",
    "\n",
    "# Put in the name of your image\n",
    "photo=\"test-data/images/14.jpg\" ## NO NEED TO CHANGE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can run the mode we need to start the inference end point with the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_model(project_arn, model_arn, version_name, min_inference_units):\n",
    "\n",
    "    client=boto3.client('rekognition')\n",
    "\n",
    "    try:\n",
    "        # Start the model\n",
    "        print('Starting model: ' + model_arn)\n",
    "        response=client.start_project_version(ProjectVersionArn=model_arn, MinInferenceUnits=min_inference_units)\n",
    "        # Wait for the model to be in the running state\n",
    "        project_version_running_waiter = client.get_waiter('project_version_running')\n",
    "        project_version_running_waiter.wait(ProjectArn=project_arn, VersionNames=[version_name])\n",
    "\n",
    "        #Get the running status\n",
    "        describe_response=client.describe_project_versions(ProjectArn=project_arn,\n",
    "            VersionNames=[version_name])\n",
    "        for model in describe_response['ProjectVersionDescriptions']:\n",
    "            print(\"Status: \" + model['Status'])\n",
    "            print(\"Message: \" + model['StatusMessage']) \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "    print('Done...')\n",
    "    \n",
    "def startmodel():\n",
    "    min_inference_units=1 \n",
    "    start_model(project_arn, model_arn, version_name, min_inference_units)\n",
    "    \n",
    "startmodel();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we setup the code that will allow us to analyze the image, but we won't start the analysis yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(bucket,photo,response):\n",
    "    # Load image from S3 bucket\n",
    "    s3_connection = boto3.resource('s3')\n",
    "\n",
    "    s3_object = s3_connection.Object(bucket,photo)\n",
    "    s3_response = s3_object.get()\n",
    "\n",
    "    stream = io.BytesIO(s3_response['Body'].read())\n",
    "    image=Image.open(stream)\n",
    "\n",
    "    # Ready image to draw bounding boxes on it.\n",
    "    imgWidth, imgHeight = image.size\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    lcount = 0\n",
    "    # calculate and display bounding boxes for each detected custom label\n",
    "    print('Detected custom labels for ' + photo)\n",
    "    for customLabel in response['CustomLabels']:\n",
    "        if 'Geometry' in customLabel and customLabel['Name'] == 'hole' :\n",
    "            box = customLabel['Geometry']['BoundingBox']\n",
    "            left = imgWidth * box['Left']\n",
    "            top = imgHeight * box['Top']\n",
    "            width = imgWidth * box['Width']\n",
    "            height = imgHeight * box['Height']\n",
    "            lcount = lcount + 1\n",
    "            print (\"-------------------------------------------------\")\n",
    "            print ('Label ' + str(lcount) + \":\")\n",
    "            print('Label Name :' + str(customLabel['Name']))\n",
    "            print('Confidence ' + str(customLabel['Confidence']))\n",
    "            # fnt = ImageFont.truetype('/Library/Fonts/Arial.ttf', 50)\n",
    "            fnt = ImageFont.truetype('/usr/share/fonts/dejavu/DejaVuSans.ttf', 50)\n",
    "            \n",
    "            draw.text((left,top), customLabel['Name'], fill='#00d400', font=fnt)\n",
    "\n",
    "            print('Left: ' + '{0:.0f}'.format(left))\n",
    "            print('Top: ' + '{0:.0f}'.format(top))\n",
    "            print('Label Width: ' + \"{0:.0f}\".format(width))\n",
    "            print('Label Height: ' + \"{0:.0f}\".format(height))\n",
    "            print (\"-------------------------------------------------\")\n",
    "            \n",
    "            points = (\n",
    "                (left,top),\n",
    "                (left + width, top),\n",
    "                (left + width, top + height),\n",
    "                (left , top + height),\n",
    "                (left, top))\n",
    "            draw.line(points, fill='#00d400', width=5)\n",
    "\n",
    "        #image.show()\n",
    "    display(image)\n",
    "\n",
    "def show_custom_labels(model,bucket,photo, min_confidence):\n",
    "    client=boto3.client('rekognition')\n",
    "\n",
    "    #Call DetectCustomLabels\n",
    "    response = client.detect_custom_labels(Image={'S3Object': {'Bucket': bucket, 'Name': photo}},\n",
    "        MinConfidence=min_confidence,\n",
    "        ProjectVersionArn=model)\n",
    "\n",
    "    # For object detection use case, uncomment below code to display image.\n",
    "    display_image(bucket,photo,response)\n",
    "    count =0\n",
    "    for labels in response['CustomLabels']:\n",
    "        if labels ['Name'] == 'hole':\n",
    "            count = count + 1\n",
    "    return count\n",
    "\n",
    "def analyzeImage():\n",
    "    min_confidence=85\n",
    "    \n",
    "    label_count=show_custom_labels(model_arn,bucket_name,photo, min_confidence)\n",
    "    print(\"Number of Holes Detected: \" + str(label_count)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the final section we run the analysis of our image using the model we trained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzeImage();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we completed out analysis we can shut down the Model endpoint with the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_model(model_arn):\n",
    "\n",
    "    client=boto3.client('rekognition')\n",
    "\n",
    "    print('Stopping model:' + model_arn)\n",
    "\n",
    "    #Stop the model\n",
    "    try:\n",
    "        response=client.stop_project_version(ProjectVersionArn=model_arn)\n",
    "        status=response['Status']\n",
    "        print ('Status: ' + status)\n",
    "    except Exception as e:  \n",
    "        print(e)  \n",
    "\n",
    "    print('Done...')\n",
    "    \n",
    "def stopModel():\n",
    "    stop_model(model_arn)\n",
    "    \n",
    "stopModel();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review\n",
    "\n",
    "We covered a lot of ground in this notebook! Let's recap what we accomplished. First we uploaded the labeled data set generated by SageMaker Ground Truth labeling job to S3 bucket. We then trained model in Amazon Rekognition Custom Labels based on training data and looked at the model accuracy, precision and F1 score for the resulting model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}